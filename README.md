ğŸ“„ Policy RAG System (Ollama + Python)

A local, privacy-preserving Retrieval-Augmented Generation (RAG) system for querying internal documents such as:

Employee Handbooks

Computer / IT Usage Policies

HR, Leave, Payroll, Security documents

Built with Python, Ollama (local LLMs), Chroma vector DB, and usable via Jupyter Notebook or scripts.

ğŸš€ Key Features

100% local (no data leaves your machine)

Supports PDF, DOCX, TXT

Uses Ollama for embeddings + LLM

Persistent vector store (Chroma)

Works seamlessly across work laptop â†’ personal laptop

Fast setup using uv

ğŸ—‚ Project Structure
policy-rag/
â”‚
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ rag.ipynb            # Main Jupyter notebook
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ loaders.py           # PDF / DOCX / TXT loaders
â”‚   â”œâ”€â”€ ingest.py            # Document ingestion & indexing
â”‚   â”œâ”€â”€ query.py             # CLI querying
â”‚   â””â”€â”€ config.py            # Central configuration
â”‚
â”œâ”€â”€ data_sample/             # Public dummy documents (optional)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md


âš ï¸ Do NOT commit real company documents or the db/ folder

ğŸ§° Prerequisites

Python 3.10+

Ollama installed and running

uv installed

Install uv (once):

pip install uv


Install Ollama from: https://ollama.com

Then pull models:

ollama pull nomic-embed-text
ollama pull llama3.1:8b


Start Ollama:

ollama serve

âš¡ Quick Start (Using uv)
1ï¸âƒ£ Clone the repository
git clone https://github.com/<your-username>/<repo-name>.git
cd <repo-name>

2ï¸âƒ£ Create environment & install dependencies
uv venv
uv pip install -r requirements.txt


Activate the environment:

Windows

.venv\Scripts\activate


macOS / Linux

source .venv/bin/activate

3ï¸âƒ£ (Optional) Register kernel for Jupyter
python -m ipykernel install --user --name policy-rag --display-name "Policy RAG (uv)"

ğŸ“¥ Add Your Documents

Create a local data/ folder (ignored by Git):

data/
 â”œâ”€â”€ Employee_Handbook.pdf
 â”œâ”€â”€ Computer_Use_Policy.docx
 â””â”€â”€ Leave_Policy.txt

ğŸ“Œ Option A: Run via Jupyter Notebook
jupyter notebook


Open:

notebook/rag.ipynb


Select kernel:

Policy RAG (uv)


Run cells top â†’ bottom:

Load documents

Chunk + embed

Store in Chroma

Ask questions

Example question:

ask("What is the annual leave policy during probation?")

ğŸ“Œ Option B: Run via Python scripts
Ingest documents
python -m src.ingest

Query documents
python -m src.query "What is the IT policy on personal device usage?"

ğŸ§  Models Used
Purpose	Model
Embeddings	nomic-embed-text
LLM	llama3.1:8b

You can change models in src/config.py.

ğŸ” Security & Compliance Notes

No cloud APIs used

No documents pushed to GitHub

Embeddings stored locally only

Suitable for confidential internal documents

ğŸ›  Common Issues

Ollama not responding

ollama serve


Retriever error
Make sure LangChain versions match requirements.txt.

Empty answers

PDFs may be scanned â†’ OCR needed

Check document text extraction

ğŸ“ˆ Future Enhancements

Page-number citations

Document-level filters (HR vs IT)

Streamlit / FastAPI UI

Reranking for higher accuracy

ğŸ“„ License

MIT (for code only â€” not documents)